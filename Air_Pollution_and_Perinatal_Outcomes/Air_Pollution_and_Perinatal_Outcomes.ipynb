{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from docx import Document\n",
    "Air_db= pd.read_spss('combine.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring the categories and continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols= ['SocioEconomic','EmergencyorElective01','Instrumentaldelivery','Diabethistory','Familyhistoryofdiabetes','Familyhistoryofpreeclampsia','AutoImmuneDisease',\n",
    "                        'hospitalized','sex','Numberofpreviouspregnanciesgravidity','Antenatalmedicationsmaternal','Birthweight_cate','PretermGrowth_cate',\n",
    "                        'FulltermGrowth_cate','AddmisionForMOrthan72HoursReason_newborn','Met1_zscore','Met2_zscore','Met3_zscore','ethnicities',\n",
    "                        'Macrosomia_cate','caesarean_cate','hypertension_cate','age_cate','TermStatus1preterm2fullterm_newborn','ApparentAbnormalitiesInBewBornTime_01']\n",
    "\n",
    "continous_cols= ['age','BMI','GestationalAge_newborn','NewBornWeight_newborn','NewBornHeightInAccouchement_newborn','NewBornHeadCircumference_newborn',\n",
    "                      'NewBornChestCircumference_newborn','NewBornHipCircumference_newborn','NewBornUpperArmCircumference_newborn','AG_Size_newborn','ASD_Size_newborn',\n",
    "                      'PW_Size_newborn','ACD_Size_newborn','AFD_Size_newborn','AnteriorFontanelleAnteroposteriorDiameter_newborn','AnteriorFontanelleTransverseDiameter_newborn',\n",
    "                      'neonatalintensivecareunitNICUdays','Hospitaldaycount','Met_pha1_zscore','Met_pha2_zscore','Met_pha3_zscore','AirPollution_month1','AirPollution_month2','AirPollution_month3',\n",
    "                      'AirPollution_meanfirstthreemonth','AirPollution_month4','AirPollution_month5','AirPollution_month6','AirPollution_meansecondthreemonth',\n",
    "                      'AirPollution_month7','AirPollution_month8','AirPollution_month9','AirPollution_month10','AirPollution_meanlastfourmonth']\n",
    "\n",
    "Air_db[categorical_cols] = Air_db[categorical_cols].astype(\"category\")\n",
    "Air_db[continous_cols] = Air_db[continous_cols].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "for col in continous_cols:\n",
    "    stat, p = shapiro(Air_db[col])\n",
    "    print(f'{col}: Statistic={stat:.3f}, p-value={p:.3f}')\n",
    "    if p > 0.05:\n",
    "        print('Probably normal')\n",
    "    else:\n",
    "        print('Probably not normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descrptive analysis for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target column\n",
    "preterm_column = \"TermStatus1preterm2fullterm_newborn\"\n",
    "\n",
    "# Drop target column from the list for testing against it\n",
    "categorical_cols_for_test = [col for col in categorical_cols if col != preterm_column]\n",
    "\n",
    "# Remove columns with only one unique non-missing value\n",
    "categorical_cols_for_test = [col for col in categorical_cols_for_test if Air_db[col].dropna().nunique() > 1]\n",
    "\n",
    "# Perform Chi-Square tests\n",
    "chi2_results = []\n",
    "contingency_tables = {}\n",
    "\n",
    "for col in categorical_cols_for_test:\n",
    "    # Drop rows with missing values in either the target or current column\n",
    "    valid_data = Air_db[[preterm_column, col]].dropna()\n",
    "\n",
    "    if valid_data.empty:\n",
    "        print(f\"Skipping {col} (All values missing)\")\n",
    "        continue\n",
    "\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(valid_data[preterm_column], valid_data[col])\n",
    "\n",
    "    if contingency_table.empty:\n",
    "        print(f\"Skipping {col} (Empty Contingency Table)\")\n",
    "        continue\n",
    "\n",
    "    # Chi-Square Test (explicitly set correction=False)\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table, correction=False)\n",
    "\n",
    "    # Row-wise percentages\n",
    "    percentage_table = contingency_table.div(contingency_table.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Save results\n",
    "    chi2_results.append({\n",
    "        \"Column\": col,\n",
    "        \"Chi2\": chi2,\n",
    "        \"P-Value\": p,\n",
    "        \"DoF\": dof\n",
    "    })\n",
    "\n",
    "    # Store tables\n",
    "    contingency_tables[col] = pd.concat([contingency_table, percentage_table], keys=[\"Count\", \"Percentage\"])\n",
    "\n",
    "# Compile results\n",
    "chi2_results = pd.DataFrame(chi2_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving the results in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"chi2_results_with_percentages.xlsx\") as writer:\n",
    "    chi2_results.to_excel(writer, sheet_name=\"Chi2 Results\", index=False)\n",
    "    \n",
    "    for col, table in contingency_tables.items():\n",
    "        # Truncate sheet name to 31 characters\n",
    "        safe_sheet_name = f\"Table_{col}\"[:31]\n",
    "        table.to_excel(writer, sheet_name=safe_sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptive analysis for continous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target column\n",
    "preterm_column = \"TermStatus1preterm2fullterm_newborn\"\n",
    "\n",
    "# Store results\n",
    "mw_test_results = []\n",
    "summary_stats = {}\n",
    "\n",
    "# Summary statistics (already good for nonparametric analysis)\n",
    "for col in continous_cols:\n",
    "    stats_df = Air_db.groupby(preterm_column)[col].agg(\n",
    "        mean=\"mean\",\n",
    "        std=\"std\",\n",
    "        count=\"count\",\n",
    "        min=\"min\",\n",
    "        median=\"median\",\n",
    "        max=\"max\",\n",
    "        Q1=lambda x: x.quantile(0.25),\n",
    "        Q3=lambda x: x.quantile(0.75)\n",
    "    )\n",
    "\n",
    "    stats_df[\"IQR\"] = stats_df[\"Q3\"] - stats_df[\"Q1\"]\n",
    "    summary_stats[col] = stats_df.drop(columns=[\"count\"])\n",
    "\n",
    "# Combine summary tables\n",
    "summary_df = pd.concat(summary_stats, axis=1)\n",
    "\n",
    "# Explicit group labels (SPSS-style: 1 vs 2)\n",
    "group_labels = sorted(Air_db[preterm_column].dropna().unique())\n",
    "group1_label = group_labels[0]\n",
    "group2_label = group_labels[1]\n",
    "\n",
    "# Perform Mannâ€“Whitney U test\n",
    "for col in continous_cols:\n",
    "    group1 = Air_db.loc[Air_db[preterm_column] == group1_label, col].dropna()\n",
    "    group2 = Air_db.loc[Air_db[preterm_column] == group2_label, col].dropna()\n",
    "\n",
    "    if len(group1) > 1 and len(group2) > 1:\n",
    "        u_stat, p_value = stats.mannwhitneyu(\n",
    "            group1,\n",
    "            group2,\n",
    "            alternative=\"two-sided\"\n",
    "        )\n",
    "\n",
    "        mw_test_results.append({\n",
    "            \"Variable\": col,\n",
    "            \"U-Statistic\": u_stat,\n",
    "            \"P-Value\": p_value,\n",
    "            f\"Median_{group1_label}\": group1.median(),\n",
    "            f\"Median_{group2_label}\": group2.median(),\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Skipping {col} (Not enough data in one or both groups)\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "mw_test_df = pd.DataFrame(mw_test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the result in an excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'statistical_results.xlsx'\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(\"statistical_results.xlsx\") as writer:\n",
    "    summary_df.to_excel(writer, sheet_name=\"Summary Statistics\")\n",
    "    mw_test_df.to_excel(writer, sheet_name=\"T-Test Results\")\n",
    "\n",
    "print(\"Results saved to 'statistical_results.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the air pollution columns\n",
    "pollution_cols = [\n",
    "    \"AirPollution_meanfirstthreemonth\",\n",
    "    \"AirPollution_meansecondthreemonth\",\n",
    "    \"AirPollution_meanlastfourmonth\"\n",
    "]\n",
    "\n",
    "# Loop over each column to create dummies\n",
    "for i, col in enumerate(pollution_cols, start=1):\n",
    "    q75 = Air_db[col].quantile(0.75)\n",
    "    dummy_col = f\"AirPollution{i}_Dummy\"\n",
    "    Air_db[dummy_col] = (Air_db[col] >= q75).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crude Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Ensure y is numeric\n",
    "y = pd.to_numeric(Air_db['Birthweight_cate'], errors='coerce')\n",
    "#y = pd.to_numeric(Air_db['PretermGrowth_cate'], errors='coerce')\n",
    "#y = pd.to_numeric(Air_db['FulltermGrowth_cate'], errors='coerce')\n",
    "\n",
    "###### Dummy encode binary categorical variables\n",
    "X = pd.get_dummies(Air_db[['AirPollution1_Dummy']], drop_first=True)\n",
    "#X = pd.get_dummies(Air_db[['AirPollution2_Dummy']], drop_first=True)\n",
    "#X = pd.get_dummies(Air_db[['AirPollution3_Dummy']], drop_first=True)\n",
    "\n",
    "\n",
    "###### Convert all to float (fix for bools)\n",
    "X = X.astype(float)\n",
    "\n",
    "###### Fit the model\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "model = OrderedModel(y, X, distr='logit', missing='drop')\n",
    "result = model.fit(method='bfgs', maxiter=1000, disp=True)\n",
    "print(result.summary())\n",
    "\n",
    "###### Odds Ratio\n",
    "coef = result.params\n",
    "odds_ratios = np.exp(coef)\n",
    "conf = result.conf_int()\n",
    "conf_odds = np.exp(conf)\n",
    "print(\"\\nOdds Ratio and 95% CI for AirPollution1_Dummy_True:\")\n",
    "print(f\"OR: {odds_ratios['AirPollution1_Dummy_True']}\")\n",
    "print(f\"95% CI: ({conf_odds.loc['AirPollution1_Dummy_True', 0]}, {conf_odds.loc['AirPollution1_Dummy_True', 1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Ensure y is numeric\n",
    "y = pd.to_numeric(Air_db['Birthweight_cate'], errors='coerce')\n",
    "#y = pd.to_numeric(Air_db['PretermGrowth_cate'], errors='coerce')\n",
    "#y = pd.to_numeric(Air_db['FulltermGrowth_cate'], errors='coerce')\n",
    "\n",
    "###### Dummy encode binary categorical variables\n",
    "X_cat = pd.get_dummies(Air_db[['AirPollution1_Dummy', 'sex']], drop_first=True)\n",
    "#X_cat = pd.get_dummies(Air_db[['AirPollution2_Dummy', 'sex']], drop_first=True)\n",
    "#X_cat = pd.get_dummies(Air_db[['AirPollution3_Dummy', 'sex']], drop_first=True)\n",
    "\n",
    "###### Continuous variables\n",
    "X_cont = Air_db[['age', 'BMI']]\n",
    "\n",
    "###### Combine predictors\n",
    "X = pd.concat([X_cat, X_cont], axis=1)\n",
    "\n",
    "###### Convert all to float (fix for bools)\n",
    "X = X.astype(float)\n",
    "\n",
    "###### Fit the model\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "model = OrderedModel(y, X, distr='logit', missing='drop')\n",
    "result = model.fit(method='bfgs', maxiter=1000, disp=True)\n",
    "print(result.summary())\n",
    "\n",
    "###### Odds Ratio\n",
    "coef = result.params\n",
    "odds_ratios = np.exp(coef)\n",
    "conf = result.conf_int()\n",
    "conf_odds = np.exp(conf)\n",
    "print(\"\\nOdds Ratio and 95% CI for AirPollution1_Dummy_True:\")\n",
    "print(f\"OR: {odds_ratios['AirPollution1_Dummy_True']}\")\n",
    "print(f\"95% CI: ({conf_odds.loc['AirPollution1_Dummy_True', 0]}, {conf_odds.loc['AirPollution1_Dummy_True', 1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Ensure y is numeric\n",
    "y = pd.to_numeric(Air_db['Birthweight_cate'], errors='coerce')\n",
    "#y = pd.to_numeric(Air_db['PretermGrowth_cate'], errors='coerce')\n",
    "#y = pd.to_numeric(Air_db['FulltermGrowth_cate'], errors='coerce')\n",
    "\n",
    "###### Dummy encode binary categorical variables\n",
    "X_cat = pd.get_dummies(Air_db[['AirPollution1_Dummy', 'sex']], drop_first=True)\n",
    "#X_cat = pd.get_dummies(Air_db[['AirPollution2_Dummy', 'sex']], drop_first=True)\n",
    "#X_cat = pd.get_dummies(Air_db[['AirPollution3_Dummy', 'sex']], drop_first=True)\n",
    "\n",
    "###### Other variables\n",
    "X_oth = Air_db[['age', 'BMI','SocioEconomic','Met_pha1_zscore','ethnicities']]\n",
    "#X_oth = Air_db[['age', 'BMI','SocioEconomic','Met_pha2_zscore','ethnicities']]\n",
    "#X_oth = Air_db[['age', 'BMI','SocioEconomic','Met_pha3_zscore','ethnicities']]\n",
    "\n",
    "###### Combine predictors\n",
    "X = pd.concat([X_cat, X_oth], axis=1)\n",
    "\n",
    "###### Convert all to float (fix for bools)\n",
    "X = X.astype(float)\n",
    "\n",
    "###### Fit the model\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "model = OrderedModel(y, X, distr='logit', missing='drop')\n",
    "result = model.fit(method='bfgs', maxiter=1000, disp=True)\n",
    "print(result.summary())\n",
    "\n",
    "###### Odds Ratio\n",
    "coef = result.params\n",
    "odds_ratios = np.exp(coef)\n",
    "conf = result.conf_int()\n",
    "conf_odds = np.exp(conf)\n",
    "print(\"\\nOdds Ratio and 95% CI for AirPollution1_Dummy_True:\")\n",
    "print(f\"OR: {odds_ratios['AirPollution1_Dummy_True']}\")\n",
    "print(f\"95% CI: ({conf_odds.loc['AirPollution1_Dummy_True', 0]}, {conf_odds.loc['AirPollution1_Dummy_True', 1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### Ensure y is numeric\n",
    "y = pd.to_numeric(Air_db['Birthweight_cate'], errors='coerce')\n",
    "#y = pd.to_numeric(Air_db['PretermGrowth_cate'], errors='coerce')\n",
    "#y = pd.to_numeric(Air_db['FulltermGrowth_cate'], errors='coerce')\n",
    "\n",
    "###### Dummy encode binary categorical variables\n",
    "X_cat = pd.get_dummies(Air_db[['AirPollution1_Dummy', 'sex','ApparentAbnormalitiesInBewBornTime_01','EmergencyorElective01']], drop_first=True)\n",
    "#X_cat = pd.get_dummies(Air_db[['AirPollution2_Dummy', 'sex','ApparentAbnormalitiesInBewBornTime_01','EmergencyorElective01']], drop_first=True)\n",
    "#X_cat = pd.get_dummies(Air_db[['AirPollution3_Dummy', 'sex','ApparentAbnormalitiesInBewBornTime_01','EmergencyorElective01']], drop_first=True)\n",
    "\n",
    "###### Other variables\n",
    "X_oth = Air_db[['age', 'BMI','SocioEconomic','Met_pha1_zscore','ethnicities']]\n",
    "#X_oth = Air_db[['age', 'BMI','SocioEconomic','Met_pha2_zscore','ethnicities']]\n",
    "#X_oth = Air_db[['age', 'BMI','SocioEconomic','Met_pha3_zscore','ethnicities']]\n",
    "\n",
    "\n",
    "###### Combine predictors\n",
    "X = pd.concat([X_cat, X_oth], axis=1)\n",
    "\n",
    "###### Convert all to float (fix for bools)\n",
    "X = X.astype(float)\n",
    "\n",
    "###### Fit the model\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "model = OrderedModel(y, X, distr='logit', missing='drop')\n",
    "result = model.fit(method='bfgs', maxiter=1000, disp=True)\n",
    "print(result.summary())\n",
    "\n",
    "###### Odds Ratio\n",
    "coef = result.params\n",
    "odds_ratios = np.exp(coef)\n",
    "conf = result.conf_int()\n",
    "conf_odds = np.exp(conf)\n",
    "print(\"\\nOdds Ratio and 95% CI for AirPollution1_Dummy_True:\")\n",
    "print(f\"OR: {odds_ratios['AirPollution1_Dummy_True']}\")\n",
    "print(f\"95% CI: ({conf_odds.loc['AirPollution1_Dummy_True', 0]}, {conf_odds.loc['AirPollution1_Dummy_True', 1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal Logistic Regression by Cold and Warm Seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crude Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each season\n",
    "for season, df_season in Air_db.groupby('season'):\n",
    "    print(f\"\\n\\n####### Results for Season: {season} #######\\n\")\n",
    "    ###### Ensure y is numeric\n",
    "    y = pd.to_numeric(df_season['Birthweight_cate'], errors='coerce')\n",
    "    #y = pd.to_numeric(df_season['PretermGrowth_cate'], errors='coerce')\n",
    "    #y = pd.to_numeric(df_season['FulltermGrowth_cate'], errors='coerce')\n",
    "\n",
    "    ###### Dummy encode binary categorical variables\n",
    "    X = pd.get_dummies(df_season[['AirPollution1_Dummy']], drop_first=True)\n",
    "    #X = pd.get_dummies(df_season[['AirPollution2_Dummy']], drop_first=True)\n",
    "    #X = pd.get_dummies(df_season[['AirPollution3_Dummy']], drop_first=True)\n",
    "\n",
    "\n",
    "    ###### Convert all to float (fix for bools)\n",
    "    X = X.astype(float)\n",
    "\n",
    "    ###### Fit the model\n",
    "    from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "    model = OrderedModel(y, X, distr='logit', missing='drop')\n",
    "\n",
    "    try:\n",
    "        result = model.fit(method='bfgs', maxiter=1000, disp=False)\n",
    "        print(result.summary())\n",
    "    except Exception as e:\n",
    "        print(f\"Model fitting failed for season {season}: {e}\")\n",
    "\n",
    "    ###### Odds Ratio\n",
    "    coef = result.params\n",
    "    odds_ratios = np.exp(coef)\n",
    "    conf = result.conf_int()\n",
    "    conf_odds = np.exp(conf)\n",
    "    print(\"\\nOdds Ratio and 95% CI for AirPollution1_Dummy_True:\")\n",
    "    print(f\"OR: {odds_ratios['AirPollution1_Dummy_True']}\")\n",
    "    print(f\"95% CI: ({conf_odds.loc['AirPollution1_Dummy_True', 0]}, {conf_odds.loc['AirPollution1_Dummy_True', 1]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each season\n",
    "for season, df_season in Air_db.groupby('season'):\n",
    "    print(f\"\\n\\n####### Results for Season: {season} #######\\n\")\n",
    "    ###### Ensure y is numeric\n",
    "    y = pd.to_numeric(df_season['Birthweight_cate'], errors='coerce')\n",
    "    #y = pd.to_numeric(df_season['PretermGrowth_cate'], errors='coerce')\n",
    "    #y = pd.to_numeric(df_season['FulltermGrowth_cate'], errors='coerce')\n",
    "\n",
    "    ###### Dummy encode binary categorical variables\n",
    "    X_cat = pd.get_dummies(df_season[['AirPollution1_Dummy', 'sex']], drop_first=True)\n",
    "    #X_cat = pd.get_dummies(df_season[['AirPollution2_Dummy', 'sex']], drop_first=True)\n",
    "    #X_cat = pd.get_dummies(df_season[['AirPollution3_Dummy', 'sex']], drop_first=True)\n",
    "\n",
    "    ###### Continuous variables\n",
    "    X_cont = df_season[['age', 'BMI']]\n",
    "\n",
    "    ###### Combine predictors\n",
    "    X = pd.concat([X_cat, X_cont], axis=1)\n",
    "\n",
    "    ###### Convert all to float (fix for bools)\n",
    "    X = X.astype(float)\n",
    "\n",
    "    ###### Fit the model\n",
    "    from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "    model = OrderedModel(y, X, distr='logit', missing='drop')\n",
    "    try:\n",
    "        result = model.fit(method='bfgs', maxiter=1000, disp=False)\n",
    "        print(result.summary())\n",
    "    except Exception as e:\n",
    "        print(f\"Model fitting failed for season {season}: {e}\")\n",
    "        \n",
    "    ###### Odds Ratio\n",
    "    coef = result.params\n",
    "    odds_ratios = np.exp(coef)\n",
    "    conf = result.conf_int()\n",
    "    conf_odds = np.exp(conf)\n",
    "    print(\"\\nOdds Ratio and 95% CI for AirPollution1_Dummy_True:\")\n",
    "    print(f\"OR: {odds_ratios['AirPollution1_Dummy_True']}\")\n",
    "    print(f\"95% CI: ({conf_odds.loc['AirPollution1_Dummy_True', 0]}, {conf_odds.loc['AirPollution1_Dummy_True', 1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each season\n",
    "for season, df_season in Air_db.groupby('season'):\n",
    "    print(f\"\\n\\n####### Results for Season: {season} #######\\n\")\n",
    "\n",
    "    ###### Ensure y is numeric\n",
    "    y = pd.to_numeric(df_season['Birthweight_cate'], errors='coerce')\n",
    "    #y = pd.to_numeric(df_season['PretermGrowth_cate'], errors='coerce')\n",
    "    #y = pd.to_numeric(df_season['FulltermGrowth_cate'], errors='coerce')\n",
    "\n",
    "    ###### Dummy encode binary categorical variables\n",
    "    X_cat = pd.get_dummies(df_season[['AirPollution1_Dummy', 'sex']], drop_first=True)\n",
    "    #X_cat = pd.get_dummies(df_season[['AirPollution2_Dummy', 'sex']], drop_first=True)\n",
    "    #X_cat = pd.get_dummies(df_season[['AirPollution3_Dummy', 'sex']], drop_first=True)\n",
    "\n",
    "    ###### Other variables\n",
    "    X_oth = df_season[['age', 'BMI','SocioEconomic','Met_pha1_zscore','ethnicities']]\n",
    "    #X_oth = df_season[['age', 'BMI','SocioEconomic','Met_pha2_zscore','ethnicities']]\n",
    "    #X_oth = df_season[['age', 'BMI','SocioEconomic','Met_pha3_zscore','ethnicities']]\n",
    "\n",
    "    ###### Combine predictors\n",
    "    X = pd.concat([X_cat, X_oth], axis=1)\n",
    "\n",
    "    ###### Convert all to float (fix for bools)\n",
    "    X = X.astype(float)\n",
    "\n",
    "    ###### Fit the model\n",
    "    from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "    model = OrderedModel(y, X, distr='logit', missing='drop')\n",
    "    try:\n",
    "        result = model.fit(method='bfgs', maxiter=1000, disp=False)\n",
    "        print(result.summary())\n",
    "    except Exception as e:\n",
    "        print(f\"Model fitting failed for season {season}: {e}\")\n",
    "        \n",
    "    ###### Odds Ratio\n",
    "    coef = result.params\n",
    "    odds_ratios = np.exp(coef)\n",
    "    conf = result.conf_int()\n",
    "    conf_odds = np.exp(conf)\n",
    "    print(\"\\nOdds Ratio and 95% CI for AirPollution1_Dummy_True:\")\n",
    "    print(f\"OR: {odds_ratios['AirPollution1_Dummy_True']}\")\n",
    "    print(f\"95% CI: ({conf_odds.loc['AirPollution1_Dummy_True', 0]}, {conf_odds.loc['AirPollution1_Dummy_True', 1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "\n",
    "# Loop over each season\n",
    "for season, df_season in Air_db.groupby('season'):\n",
    "\n",
    "    print(f\"\\n\\n####### Results for Season: {season} #######\\n\")\n",
    "\n",
    "    ###### Ensure y is numeric\n",
    "    y = pd.to_numeric(df_season['Birthweight_cate'], errors='coerce')\n",
    "    #y = pd.to_numeric(df_season['PretermGrowth_cate'], errors='coerce')\n",
    "    #y = pd.to_numeric(df_season['FulltermGrowth_cate'], errors='coerce')\n",
    "    \n",
    "    ###### Dummy encode binary categorical variables\n",
    "    X_cat = pd.get_dummies(df_season[['AirPollution1_Dummy', 'sex', 'ApparentAbnormalitiesInBewBornTime_01','EmergencyorElective01']], drop_first=True)\n",
    "    #X_cat = pd.get_dummies(df_season[['AirPollution2_Dummy', 'sex', 'ApparentAbnormalitiesInBewBornTime_01','EmergencyorElective01']], drop_first=True)\n",
    "    #X_cat = pd.get_dummies(df_season[['AirPollution3_Dummy', 'sex', 'ApparentAbnormalitiesInBewBornTime_01','EmergencyorElective01']], drop_first=True)\n",
    "\n",
    "    ###### Other variables\n",
    "    X_oth = df_season[['age', 'BMI', 'SocioEconomic', 'Met_pha1_zscore', 'ethnicities']]\n",
    "    #X_oth = df_season[['age', 'BMI', 'SocioEconomic', 'Met_pha2_zscore', 'ethnicities']]\n",
    "    #X_oth = df_season[['age', 'BMI', 'SocioEconomic', 'Met_pha3_zscore', 'ethnicities']]\n",
    "\n",
    "    ###### Combine predictors\n",
    "    X = pd.concat([X_cat, X_oth], axis=1)\n",
    "\n",
    "    ###### Convert all to float (fix for bools)\n",
    "    X = X.astype(float)\n",
    "\n",
    "    ###### Fit the model\n",
    "    model = OrderedModel(y, X, distr='logit', missing='drop')\n",
    "    \n",
    "    try:\n",
    "        result = model.fit(method='bfgs', maxiter=1000, disp=False)\n",
    "        print(result.summary())\n",
    "    except Exception as e:\n",
    "        print(f\"Model fitting failed for season {season}: {e}\")\n",
    "        \n",
    "    ###### Odds Ratio\n",
    "    coef = result.params\n",
    "    odds_ratios = np.exp(coef)\n",
    "    conf = result.conf_int()\n",
    "    conf_odds = np.exp(conf)\n",
    "    print(\"\\nOdds Ratio and 95% CI for AirPollution1_Dummy_True:\")\n",
    "    print(f\"OR: {odds_ratios['AirPollution1_Dummy_True']}\")\n",
    "    print(f\"95% CI: ({conf_odds.loc['AirPollution1_Dummy_True', 0]}, {conf_odds.loc['AirPollution1_Dummy_True', 1]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
